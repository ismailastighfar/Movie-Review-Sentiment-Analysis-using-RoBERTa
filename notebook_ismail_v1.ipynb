{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10025,"databundleVersionId":32092,"sourceType":"competition"},{"sourceId":6897,"sourceType":"datasetVersion","datasetId":4511}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport transformers\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import RobertaModel, RobertaTokenizer\n\nimport logging\nlogging.basicConfig(level=logging.ERROR)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:28.058567Z","iopub.execute_input":"2024-02-10T10:58:28.059309Z","iopub.status.idle":"2024-02-10T10:58:35.599956Z","shell.execute_reply.started":"2024-02-10T10:58:28.059279Z","shell.execute_reply":"2024-02-10T10:58:35.599170Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\nfrom torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:35.601609Z","iopub.execute_input":"2024-02-10T10:58:35.602047Z","iopub.status.idle":"2024-02-10T10:58:35.625291Z","shell.execute_reply.started":"2024-02-10T10:58:35.602021Z","shell.execute_reply":"2024-02-10T10:58:35.624356Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/movie-review-sentiment-analysis-kernels-only/train.tsv.zip', delimiter='\\t')","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:35.630604Z","iopub.execute_input":"2024-02-10T10:58:35.630947Z","iopub.status.idle":"2024-02-10T10:58:35.883397Z","shell.execute_reply.started":"2024-02-10T10:58:35.630916Z","shell.execute_reply":"2024-02-10T10:58:35.882397Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:35.884560Z","iopub.execute_input":"2024-02-10T10:58:35.884847Z","iopub.status.idle":"2024-02-10T10:58:35.891622Z","shell.execute_reply.started":"2024-02-10T10:58:35.884824Z","shell.execute_reply":"2024-02-10T10:58:35.890708Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(156060, 4)"},"metadata":{}}]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:35.892728Z","iopub.execute_input":"2024-02-10T10:58:35.893005Z","iopub.status.idle":"2024-02-10T10:58:35.909322Z","shell.execute_reply.started":"2024-02-10T10:58:35.892983Z","shell.execute_reply":"2024-02-10T10:58:35.908463Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   PhraseId  SentenceId                                             Phrase  \\\n0         1           1  A series of escapades demonstrating the adage ...   \n1         2           1  A series of escapades demonstrating the adage ...   \n2         3           1                                           A series   \n3         4           1                                                  A   \n4         5           1                                             series   \n\n   Sentiment  \n0          1  \n1          2  \n2          2  \n3          2  \n4          2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PhraseId</th>\n      <th>SentenceId</th>\n      <th>Phrase</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>A series of escapades demonstrating the adage ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>A series of escapades demonstrating the adage ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>A series</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>A</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>series</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['Sentiment'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:35.910422Z","iopub.execute_input":"2024-02-10T10:58:35.910758Z","iopub.status.idle":"2024-02-10T10:58:35.920419Z","shell.execute_reply.started":"2024-02-10T10:58:35.910728Z","shell.execute_reply":"2024-02-10T10:58:35.919469Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"array([1, 2, 3, 4, 0])"},"metadata":{}}]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:35.921449Z","iopub.execute_input":"2024-02-10T10:58:35.921684Z","iopub.status.idle":"2024-02-10T10:58:35.952955Z","shell.execute_reply.started":"2024-02-10T10:58:35.921664Z","shell.execute_reply":"2024-02-10T10:58:35.952121Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"            PhraseId     SentenceId      Sentiment\ncount  156060.000000  156060.000000  156060.000000\nmean    78030.500000    4079.732744       2.063578\nstd     45050.785842    2502.764394       0.893832\nmin         1.000000       1.000000       0.000000\n25%     39015.750000    1861.750000       2.000000\n50%     78030.500000    4017.000000       2.000000\n75%    117045.250000    6244.000000       3.000000\nmax    156060.000000    8544.000000       4.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PhraseId</th>\n      <th>SentenceId</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>156060.000000</td>\n      <td>156060.000000</td>\n      <td>156060.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>78030.500000</td>\n      <td>4079.732744</td>\n      <td>2.063578</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>45050.785842</td>\n      <td>2502.764394</td>\n      <td>0.893832</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>39015.750000</td>\n      <td>1861.750000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>78030.500000</td>\n      <td>4017.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>117045.250000</td>\n      <td>6244.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>156060.000000</td>\n      <td>8544.000000</td>\n      <td>4.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"new_df = train[['Phrase', 'Sentiment']]\nnew_df","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:35.954156Z","iopub.execute_input":"2024-02-10T10:58:35.954476Z","iopub.status.idle":"2024-02-10T10:58:35.972245Z","shell.execute_reply.started":"2024-02-10T10:58:35.954447Z","shell.execute_reply":"2024-02-10T10:58:35.971342Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                   Phrase  Sentiment\n0       A series of escapades demonstrating the adage ...          1\n1       A series of escapades demonstrating the adage ...          2\n2                                                A series          2\n3                                                       A          2\n4                                                  series          2\n...                                                   ...        ...\n156055                                          Hearst 's          2\n156056                          forced avuncular chortles          1\n156057                                 avuncular chortles          3\n156058                                          avuncular          2\n156059                                           chortles          2\n\n[156060 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Phrase</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A series of escapades demonstrating the adage ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A series of escapades demonstrating the adage ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A series</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>series</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>156055</th>\n      <td>Hearst 's</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>156056</th>\n      <td>forced avuncular chortles</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>156057</th>\n      <td>avuncular chortles</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>156058</th>\n      <td>avuncular</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>156059</th>\n      <td>chortles</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>156060 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\n\nMAX_LEN = 52\n\nTRAIN_BATCH_SIZE = 64\n\nVALID_BATCH_SIZE = 64\n\nLEARNING_RATE = 1e-5\n\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:35.976089Z","iopub.execute_input":"2024-02-10T10:58:35.976598Z","iopub.status.idle":"2024-02-10T10:58:39.138898Z","shell.execute_reply.started":"2024-02-10T10:58:35.976575Z","shell.execute_reply":"2024-02-10T10:58:39.137899Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc8872a8627845cebb7b690e946cbbc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a47a715f9bf442eeae45e0433c4cd425"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7566e53351b14a3e8a81ba32e3407ac4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"833b7ad536b541b5a0535bbbb350ede4"}},"metadata":{}}]},{"cell_type":"code","source":"class SentimentData(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.text = dataframe.Phrase\n        self.targets = self.data.Sentiment\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, index):\n        text = str(self.text[index])\n        text = \" \".join(text.split())\n\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            truncation=True,\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n\n\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:39.140171Z","iopub.execute_input":"2024-02-10T10:58:39.140528Z","iopub.status.idle":"2024-02-10T10:58:39.151201Z","shell.execute_reply.started":"2024-02-10T10:58:39.140497Z","shell.execute_reply":"2024-02-10T10:58:39.150195Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_size = 0.8\ntrain_data=new_df.sample(frac=train_size,random_state=200)\ntest_data=new_df.drop(train_data.index).reset_index(drop=True)\ntrain_data = train_data.reset_index(drop=True)\n\n\nprint(\"FULL Dataset: {}\".format(new_df.shape))\nprint(\"TRAIN Dataset: {}\".format(train_data.shape))\nprint(\"TEST Dataset: {}\".format(test_data.shape))\n\ntraining_set = SentimentData(train_data, tokenizer, MAX_LEN)\ntesting_set = SentimentData(test_data, tokenizer, MAX_LEN)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:39.152478Z","iopub.execute_input":"2024-02-10T10:58:39.152835Z","iopub.status.idle":"2024-02-10T10:58:39.210022Z","shell.execute_reply.started":"2024-02-10T10:58:39.152804Z","shell.execute_reply":"2024-02-10T10:58:39.209076Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"FULL Dataset: (156060, 2)\nTRAIN Dataset: (124848, 2)\nTEST Dataset: (31212, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"\ntrain_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 4\n                }\n\ntest_params = {'batch_size': VALID_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 4\n                }\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:39.211216Z","iopub.execute_input":"2024-02-10T10:58:39.211571Z","iopub.status.idle":"2024-02-10T10:58:39.217796Z","shell.execute_reply.started":"2024-02-10T10:58:39.211539Z","shell.execute_reply":"2024-02-10T10:58:39.216751Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Creating the Neural Network for Fine Tuning","metadata":{}},{"cell_type":"code","source":"class RobertaClass(torch.nn.Module):\n    def __init__(self):\n        super(RobertaClass, self).__init__()\n        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n        self.pre_classifier = torch.nn.Linear(768, 768)\n    \n        self.dropout = torch.nn.Dropout(0.5)\n     \n        self.classifier = torch.nn.Linear(768, 5)\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n    \n        hidden_state = output_1[0]\n     \n        pooler = hidden_state[:, 0]\n        pooler = self.pre_classifier(pooler)\n       \n        pooler = torch.nn.ReLU()(pooler)\n        pooler = self.dropout(pooler)\n        output = self.classifier(pooler)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:39.218974Z","iopub.execute_input":"2024-02-10T10:58:39.219270Z","iopub.status.idle":"2024-02-10T10:58:39.228902Z","shell.execute_reply.started":"2024-02-10T10:58:39.219246Z","shell.execute_reply":"2024-02-10T10:58:39.228005Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = RobertaClass()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:39.230007Z","iopub.execute_input":"2024-02-10T10:58:39.230266Z","iopub.status.idle":"2024-02-10T10:58:54.571385Z","shell.execute_reply.started":"2024-02-10T10:58:39.230244Z","shell.execute_reply":"2024-02-10T10:58:54.570401Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"197b2e512ac74cfa843d725aa2155c10"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"RobertaClass(\n  (l1): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (dropout): Dropout(p=0.5, inplace=False)\n  (classifier): Linear(in_features=768, out_features=5, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"loss_function = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE,weight_decay=1e-5)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:54.573077Z","iopub.execute_input":"2024-02-10T10:58:54.573724Z","iopub.status.idle":"2024-02-10T10:58:54.579864Z","shell.execute_reply.started":"2024-02-10T10:58:54.573667Z","shell.execute_reply":"2024-02-10T10:58:54.578937Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def calcuate_accuracy(preds, targets):\n    n_correct = (preds==targets).sum().item()\n    return n_correct","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:54.580993Z","iopub.execute_input":"2024-02-10T10:58:54.581253Z","iopub.status.idle":"2024-02-10T10:58:54.593252Z","shell.execute_reply.started":"2024-02-10T10:58:54.581226Z","shell.execute_reply":"2024-02-10T10:58:54.592562Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"\n\ndef train(epoch):\n   \n    tr_loss = 0\n   \n    n_correct = 0\n    \n    nb_tr_steps = 0\n    nb_tr_examples = 0\n\n    \n    model.train()\n\n    for _,data in tqdm(enumerate(training_loader, 0)):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.long)\n\n       \n        outputs = model(ids, mask, token_type_ids)\n\n       \n        loss = loss_function(outputs, targets)\n        tr_loss += loss.item()\n\n       \n        big_val, big_idx = torch.max(outputs.data, dim=1)\n        n_correct += calcuate_accuracy(big_idx, targets)\n\n     \n        nb_tr_steps += 1\n        nb_tr_examples+=targets.size(0)\n\n       \n        if _%5000==0:\n            loss_step = tr_loss/nb_tr_steps\n            accu_step = (n_correct*100)/nb_tr_examples\n            print(f\"Training Loss per 5000 steps: {loss_step}\")\n            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n\n       \n        optimizer.zero_grad()\n        loss.backward()\n      \n        optimizer.step()\n    \n    \n    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n    epoch_loss = tr_loss/nb_tr_steps\n    epoch_accu = (n_correct*100)/nb_tr_examples\n    print(f\"Training Loss Epoch: {epoch_loss}\")\n    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n\n    return","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:54.594254Z","iopub.execute_input":"2024-02-10T10:58:54.594787Z","iopub.status.idle":"2024-02-10T10:58:54.604545Z","shell.execute_reply.started":"2024-02-10T10:58:54.594764Z","shell.execute_reply":"2024-02-10T10:58:54.603656Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 5\nfor epoch in range(EPOCHS):\n    train(epoch)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T10:58:54.605681Z","iopub.execute_input":"2024-02-10T10:58:54.605958Z","iopub.status.idle":"2024-02-10T11:47:42.953025Z","shell.execute_reply.started":"2024-02-10T10:58:54.605936Z","shell.execute_reply":"2024-02-10T11:47:42.951940Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Training Loss per 5000 steps: 1.6614089012145996\nTraining Accuracy per 5000 steps: 15.625\n","output_type":"stream"},{"name":"stderr","text":"1951it [09:45,  3.33it/s]","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 0: 65.20569011918492\nTraining Loss Epoch: 0.8463560834656857\nTraining Accuracy Epoch: 65.20569011918492\n","output_type":"stream"},{"name":"stderr","text":"\n1it [00:00,  4.16it/s]","output_type":"stream"},{"name":"stdout","text":"Training Loss per 5000 steps: 0.8710432052612305\nTraining Accuracy per 5000 steps: 59.375\n","output_type":"stream"},{"name":"stderr","text":"1951it [09:45,  3.33it/s]","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 1: 69.8024798154556\nTraining Loss Epoch: 0.7252132300839309\nTraining Accuracy Epoch: 69.8024798154556\n","output_type":"stream"},{"name":"stderr","text":"\n1it [00:00,  4.99it/s]","output_type":"stream"},{"name":"stdout","text":"Training Loss per 5000 steps: 0.6515316963195801\nTraining Accuracy per 5000 steps: 73.4375\n","output_type":"stream"},{"name":"stderr","text":"1951it [09:45,  3.33it/s]","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 2: 71.69918621043189\nTraining Loss Epoch: 0.6770083618616215\nTraining Accuracy Epoch: 71.69918621043189\n","output_type":"stream"},{"name":"stderr","text":"\n1it [00:00,  4.33it/s]","output_type":"stream"},{"name":"stdout","text":"Training Loss per 5000 steps: 0.8445261716842651\nTraining Accuracy per 5000 steps: 57.8125\n","output_type":"stream"},{"name":"stderr","text":"1951it [09:45,  3.33it/s]","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 3: 73.39965397923875\nTraining Loss Epoch: 0.6399519480478452\nTraining Accuracy Epoch: 73.39965397923875\n","output_type":"stream"},{"name":"stderr","text":"\n1it [00:00,  4.75it/s]","output_type":"stream"},{"name":"stdout","text":"Training Loss per 5000 steps: 0.5559527277946472\nTraining Accuracy per 5000 steps: 75.0\n","output_type":"stream"},{"name":"stderr","text":"1951it [09:44,  3.34it/s]","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 4: 75.03123798539023\nTraining Loss Epoch: 0.6044249981565393\nTraining Accuracy Epoch: 75.03123798539023\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"def valid(model, testing_loader):\n\n  \n    model.eval()\n\n    n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n\n   \n    with torch.no_grad():\n        for _, data in tqdm(enumerate(testing_loader, 0)):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n            targets = data['targets'].to(device, dtype = torch.long)\n            outputs = model(ids, mask, token_type_ids).squeeze()\n\n           \n            loss = loss_function(outputs, targets)\n            tr_loss += loss.item()\n            big_val, big_idx = torch.max(outputs.data, dim=1)\n            n_correct += calcuate_accuracy(big_idx, targets)\n\n            nb_tr_steps += 1\n            nb_tr_examples+=targets.size(0)\n\n          \n            if _%5000==0:\n                loss_step = tr_loss/nb_tr_steps\n                accu_step = (n_correct*100)/nb_tr_examples\n                print(f\"Validation Loss per 100 steps: {loss_step}\")\n                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n                \n \n    epoch_loss = tr_loss/nb_tr_steps\n    epoch_accu = (n_correct*100)/nb_tr_examples\n    print(f\"Validation Loss Epoch: {epoch_loss}\")\n    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n\n    return epoch_accu","metadata":{"execution":{"iopub.status.busy":"2024-02-10T11:47:42.955008Z","iopub.execute_input":"2024-02-10T11:47:42.955309Z","iopub.status.idle":"2024-02-10T11:47:42.966356Z","shell.execute_reply.started":"2024-02-10T11:47:42.955280Z","shell.execute_reply":"2024-02-10T11:47:42.965314Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"acc = valid(model, testing_loader)\nprint(\"Accuracy on test data = %0.2f%%\" % acc)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T11:47:42.967641Z","iopub.execute_input":"2024-02-10T11:47:42.967955Z","iopub.status.idle":"2024-02-10T11:48:31.498236Z","shell.execute_reply.started":"2024-02-10T11:47:42.967931Z","shell.execute_reply":"2024-02-10T11:48:31.497157Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"2it [00:00,  7.46it/s]","output_type":"stream"},{"name":"stdout","text":"Validation Loss per 100 steps: 0.5872433185577393\nValidation Accuracy per 100 steps: 75.0\n","output_type":"stream"},{"name":"stderr","text":"488it [00:48, 10.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Epoch: 0.733800831266114\nValidation Accuracy Epoch: 70.23901063693451\nAccuracy on test data = 70.24%\n","output_type":"stream"}]}]}